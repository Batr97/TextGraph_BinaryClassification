{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from typing import Dict, Optional, Tuple, List\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, classification_report\n",
    "\n",
    "import dgl\n",
    "from dgl.data import MiniGCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_path = \"../data/tsv/train.tsv\"\n",
    "test_path = \"../data/tsv/test.tsv\"\n",
    "\n",
    "test_df = pd.read_csv(test_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSimpleClassifier(nn.Module):\n",
    "    def __init__(self, bert_text_encoder, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert_text_encoder = bert_text_encoder\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        bert_hidden_dim = bert_text_encoder.config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bert_hidden_dim, bert_hidden_dim),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bert_hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs, attention_mask,):\n",
    "        last_hidden_states = self.bert_text_encoder(inputs, attention_mask=attention_mask,\n",
    "                                                    return_dict=True)['last_hidden_state']\n",
    "        text_cls_embeddings = torch.stack([elem[0, :] for elem in last_hidden_states])\n",
    "        proba = self.classifier(text_cls_embeddings)\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hekmat/personal/anaconda3/envs/GAT/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Trainable params:  50206080\n"
     ]
    }
   ],
   "source": [
    "# model_name=\"roberta-base\"\n",
    "model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "freeze_embeddings = True\n",
    "if freeze_embeddings:\n",
    "    for param in bert_model.embeddings.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "freeze_layer_count = 5\n",
    "if freeze_layer_count > 0:\n",
    "    for layer in bert_model.encoder.layer[:freeze_layer_count]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "print(\"# Trainable params: \", sum(p.numel() for p in bert_model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "DROPOUT = 0.2\n",
    "\n",
    "bert_simple_clf = BertSimpleClassifier(bert_model, dropout=DROPOUT).to(device)\n",
    "optimizer = optim.Adam(bert_simple_clf.parameters(), lr=3e-5)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_simple_clf_trained = BertSimpleClassifier(bert_model, dropout=DROPOUT).to(device)\n",
    "bert_simple_clf_trained.load_state_dict(torch.load('./best-val-text_only_baseline.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>question</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntityId</th>\n",
       "      <th>answerEntityId</th>\n",
       "      <th>graph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>After publishing A Time to Kill, which book di...</td>\n",
       "      <td>A Time to Kill</td>\n",
       "      <td>A Clash of Kings</td>\n",
       "      <td>Q1213715</td>\n",
       "      <td>Q300370</td>\n",
       "      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>After publishing A Time to Kill, which book di...</td>\n",
       "      <td>A Time to Kill</td>\n",
       "      <td>A Feast for Crows</td>\n",
       "      <td>Q1213715</td>\n",
       "      <td>Q1764445</td>\n",
       "      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>After publishing A Time to Kill, which book di...</td>\n",
       "      <td>A Time to Kill</td>\n",
       "      <td>Fear and Loathing in Las Vegas</td>\n",
       "      <td>Q1213715</td>\n",
       "      <td>Q772435</td>\n",
       "      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>After publishing A Time to Kill, which book di...</td>\n",
       "      <td>A Time to Kill</td>\n",
       "      <td>In Cold Blood</td>\n",
       "      <td>Q1213715</td>\n",
       "      <td>Q1142887</td>\n",
       "      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>After publishing A Time to Kill, which book di...</td>\n",
       "      <td>A Time to Kill</td>\n",
       "      <td>Into the Woods</td>\n",
       "      <td>Q1213715</td>\n",
       "      <td>Q1118244</td>\n",
       "      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                           question  \\\n",
       "0          0  After publishing A Time to Kill, which book di...   \n",
       "1          1  After publishing A Time to Kill, which book di...   \n",
       "2          2  After publishing A Time to Kill, which book di...   \n",
       "3          3  After publishing A Time to Kill, which book di...   \n",
       "4          4  After publishing A Time to Kill, which book di...   \n",
       "\n",
       "   questionEntity                    answerEntity questionEntityId  \\\n",
       "0  A Time to Kill                A Clash of Kings         Q1213715   \n",
       "1  A Time to Kill               A Feast for Crows         Q1213715   \n",
       "2  A Time to Kill  Fear and Loathing in Las Vegas         Q1213715   \n",
       "3  A Time to Kill                   In Cold Blood         Q1213715   \n",
       "4  A Time to Kill                  Into the Woods         Q1213715   \n",
       "\n",
       "  answerEntityId                                              graph  \n",
       "0        Q300370  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...  \n",
       "1       Q1764445  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...  \n",
       "2        Q772435  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...  \n",
       "3       Q1142887  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...  \n",
       "4       Q1118244  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[\"label\"] = np.zeros(shape=test_df.shape[0], dtype=np.float32)\n",
    "test_df[\"graph\"] = test_df[\"graph\"].apply(eval)\n",
    "test_df_filtered_emb = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>question</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntityId</th>\n",
       "      <th>answerEntityId</th>\n",
       "      <th>graph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>After publishing A Time to Kill, which book di...</td>\n",
       "      <td>A Time to Kill</td>\n",
       "      <td>A Clash of Kings</td>\n",
       "      <td>Q1213715</td>\n",
       "      <td>Q300370</td>\n",
       "      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>After publishing A Time to Kill, which book di...</td>\n",
       "      <td>A Time to Kill</td>\n",
       "      <td>A Feast for Crows</td>\n",
       "      <td>Q1213715</td>\n",
       "      <td>Q1764445</td>\n",
       "      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>After publishing A Time to Kill, which book di...</td>\n",
       "      <td>A Time to Kill</td>\n",
       "      <td>Fear and Loathing in Las Vegas</td>\n",
       "      <td>Q1213715</td>\n",
       "      <td>Q772435</td>\n",
       "      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>After publishing A Time to Kill, which book di...</td>\n",
       "      <td>A Time to Kill</td>\n",
       "      <td>In Cold Blood</td>\n",
       "      <td>Q1213715</td>\n",
       "      <td>Q1142887</td>\n",
       "      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>After publishing A Time to Kill, which book di...</td>\n",
       "      <td>A Time to Kill</td>\n",
       "      <td>Into the Woods</td>\n",
       "      <td>Q1213715</td>\n",
       "      <td>Q1118244</td>\n",
       "      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                           question  \\\n",
       "0          0  After publishing A Time to Kill, which book di...   \n",
       "1          1  After publishing A Time to Kill, which book di...   \n",
       "2          2  After publishing A Time to Kill, which book di...   \n",
       "3          3  After publishing A Time to Kill, which book di...   \n",
       "4          4  After publishing A Time to Kill, which book di...   \n",
       "\n",
       "   questionEntity                    answerEntity questionEntityId  \\\n",
       "0  A Time to Kill                A Clash of Kings         Q1213715   \n",
       "1  A Time to Kill               A Feast for Crows         Q1213715   \n",
       "2  A Time to Kill  Fear and Loathing in Las Vegas         Q1213715   \n",
       "3  A Time to Kill                   In Cold Blood         Q1213715   \n",
       "4  A Time to Kill                  Into the Woods         Q1213715   \n",
       "\n",
       "  answerEntityId                                              graph  \n",
       "0        Q300370  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...  \n",
       "1       Q1764445  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...  \n",
       "2        Q772435  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...  \n",
       "3       Q1142887  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...  \n",
       "4       Q1118244  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q30'...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_filtered_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10961"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df_filtered_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert None in labels to [MASK]\n",
    "def none2mask(row):\n",
    "    nodes = row['nodes']\n",
    "    edges = row['links']\n",
    "    for node in nodes:\n",
    "        if node['label'] is None:\n",
    "            node['label'] = '[MASK]'\n",
    "    for edge in edges:\n",
    "        if edge['label'] is None:\n",
    "            edge['label'] = '[MASK]'\n",
    "    return row\n",
    "\n",
    "test_df_filtered_emb['graph'] = test_df_filtered_emb['graph'].apply(none2mask)\n",
    "\n",
    "# create columns with labels of nodes and links (add [EMPTY] to empty list)\n",
    "def graph_labels(row, edges=False):\n",
    "    labels = []\n",
    "    if edges:\n",
    "        data = row['links']\n",
    "    else:\n",
    "        data = row['nodes']\n",
    "    for item in data:\n",
    "        labels.append(item['label'])\n",
    "    if len(labels)==0:\n",
    "        labels.append('[EMPTY]')\n",
    "    return labels\n",
    "\n",
    "\n",
    "test_df_filtered_emb['node_labels'] = test_df_filtered_emb['graph'].apply(graph_labels)\n",
    "test_df_filtered_emb['edge_labels'] = test_df_filtered_emb['graph'].apply(graph_labels, edges=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper func \n",
    "def create_embs(model, tokenizer, data):\n",
    "    data_token = tokenizer(data, max_length=128, padding=\"max_length\", truncation=\"only_first\", return_tensors=\"pt\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = data_token[\"input_ids\"].to(device)\n",
    "        attention_mask = data_token[\"attention_mask\"].to(device)\n",
    "        outputs = model.bert_text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        outputs = outputs.last_hidden_state.mean(dim=1)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# create columns with embeddings in format suitable for dgl.data.CSVDataset\n",
    "def label_embs(row):\n",
    "    outputs = create_embs(bert_simple_clf_trained, tokenizer, row)\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    res = []\n",
    "    for output in outputs:\n",
    "        res.append(\",\".join(map(str, output)))\n",
    "    return res\n",
    "\n",
    "test_df_filtered_emb['node_embs'] = test_df_filtered_emb['node_labels'].apply(label_embs)\n",
    "test_df_filtered_emb['edge_embs'] = test_df_filtered_emb['edge_labels'].apply(label_embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10961"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df_filtered_emb['sample_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_filtered_emb.iloc[-1,-3]\n",
    "# функция для преобразования данных графа в csv\n",
    "\n",
    "\n",
    "def graph2node_csv(graph, id_graph, node_embs, edge_embs, edges=False):\n",
    "    output = []\n",
    "    if edges:\n",
    "        # one node cases (without edges) in order to avoid errors while forming dgl dataset\n",
    "        if len(graph['links']) == 0:\n",
    "            output.append(\n",
    "                {\n",
    "                    'graph_id': id_graph,\n",
    "                    'src_id': None,\n",
    "                    'dst_id': None,\n",
    "                    'feat': ' '\n",
    "                }\n",
    "            )\n",
    "        for i, item in enumerate(graph['links']):\n",
    "            output.append(\n",
    "                {\n",
    "                    'graph_id': id_graph,\n",
    "                    'src_id': item['source'],\n",
    "                    'dst_id': item['target'],\n",
    "                    'feat': edge_embs[i]\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        for i, item in enumerate(graph['nodes']):\n",
    "            output.append(\n",
    "                {\n",
    "                    'graph_id': id_graph,\n",
    "                    'node_id': item['id'],\n",
    "                    'feat': node_embs[i]\n",
    "                }\n",
    "            )\n",
    "    return output\n",
    "\n",
    "\n",
    "test_df_filtered_emb['node_csv'] = test_df_filtered_emb.apply(lambda x: graph2node_csv(x['graph'], x['sample_id'], x['node_embs'], x['edge_embs'], edges=False), axis=1)\n",
    "test_df_filtered_emb['edge_csv'] = test_df_filtered_emb.apply(lambda x: graph2node_csv(x['graph'], x['sample_id'], x['node_embs'], x['edge_embs'], edges=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_of_nodes = test_df_filtered_emb['node_csv'].tolist()\n",
    "flattened_list_nodes = [item for sublist in lst_of_nodes for item in sublist]\n",
    "node_df = pd.DataFrame.from_records(flattened_list_nodes)\n",
    "\n",
    "lst_of_edges = test_df_filtered_emb['edge_csv'].tolist()\n",
    "flattened_list_edges = [item for sublist in lst_of_edges for item in sublist]\n",
    "edge_df = pd.DataFrame.from_records(flattened_list_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete one noode graphs for this time \n",
    "# edge_df.dropna(how='any', axis=0, inplace=True)\n",
    "node_df = node_df[node_df['graph_id'].isin(edge_df.graph_id.tolist())]\n",
    "graph_df = test_df_filtered_emb.rename(columns={'sample_id':'graph_id'}).loc[:, ['graph_id']]\n",
    "# graph_df = graph_df[graph_df['graph_id'].isin(edge_df.graph_id.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df.to_csv('../data/dataset_test/edges.csv', index=False, na_rep=' ')\n",
    "node_df.to_csv('../data/dataset_test/nodes.csv', index=False)\n",
    "\n",
    "# train_df_filtered_emb[\"label\"] = train_df_filtered_emb[\"correct\"].astype(np.float32)\n",
    "# train_df_filtered_emb.rename(columns={'sample_id':'graph_id'}).loc[:, ['graph_id', 'label']].to_csv('../data/dataset/graphs.csv', index=False)\n",
    "\n",
    "graph_df.to_csv('../data/dataset_test/graphs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph_id</th>\n",
       "      <th>src_id</th>\n",
       "      <th>dst_id</th>\n",
       "      <th>feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02993089,0.005517466,-0.108303435,0.16291112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00097008544,-0.020878252,-0.071897194,-0.001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00097008544,-0.020878252,-0.071897194,-0.001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02993089,0.005517466,-0.108303435,0.16291112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00097008544,-0.020878252,-0.071897194,-0.001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   graph_id  src_id  dst_id                                               feat\n",
       "0         0     0.0     0.0  0.02993089,0.005517466,-0.108303435,0.16291112...\n",
       "1         0     1.0     0.0  0.00097008544,-0.020878252,-0.071897194,-0.001...\n",
       "2         0     2.0     0.0  0.00097008544,-0.020878252,-0.071897194,-0.001...\n",
       "3         1     0.0     0.0  0.02993089,0.005517466,-0.108303435,0.16291112...\n",
       "4         1     1.0     0.0  0.00097008544,-0.020878252,-0.071897194,-0.001..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dgl.data.CSVDataset('../data/dataset_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import CiteseerGraphDataset, CoraGraphDataset, PubmedGraphDataset\n",
    "from dgl import AddSelfLoop\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from dgl.nn import EdgeGATConv, GraphConv\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = GraphDataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=86, num_edges=88,\n",
       "      ndata_schemes={'feat': Scheme(shape=(768,), dtype=torch.float32)}\n",
       "      edata_schemes={'feat': Scheme(shape=(768,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_data))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs = dgl.unbatch(next(iter(test_data))[0])\n",
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(samples):\n",
    "    # The input `samples` is a list of pairs\n",
    "    #  (graph, label).\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.tensor(labels)\n",
    "\n",
    "dataloader = DataLoader(test_data, batch_size=32, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([86, 768])\n",
      "torch.Size([88, 768])\n",
      "torch.Size([86, 2, 15])\n",
      "torch.Size([86, 30])\n",
      "torch.Size([86, 2, 15])\n",
      "torch.Size([86, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "g = next(iter(test_data))[0]\n",
    "\n",
    "# g = dgl.add_self_loop(g)\n",
    "# print(dgl.unbatch(g))\n",
    "print(g.ndata['feat'].shape)\n",
    "layer1 = EdgeGATConv(768, 768, 15, 2, allow_zero_in_degree=True)\n",
    "layer2 = EdgeGATConv(15*2, 768, 15, 2, allow_zero_in_degree=True)\n",
    "# layer1 = GraphConv(768, 15, allow_zero_in_degree=True)\n",
    "# layer2 = GraphConv(15, 2, allow_zero_in_degree=True)\n",
    "lin_layer = nn.Linear(15 * 2, 1)\n",
    "edge_feat = g.edata['feat']\n",
    "node_feat = g.ndata['feat']\n",
    "print(edge_feat.shape)\n",
    "out1 = layer1(g, node_feat, edge_feat, get_attention=False)\n",
    "print(out1.shape)\n",
    "print(out1.view(g.ndata['feat'].shape[0], 30).shape)\n",
    "out2 = F.relu(layer2(g, out1.view(g.ndata['feat'].shape[0], 30), edge_feat))\n",
    "print(out2.shape)\n",
    "out2 = out2.view(g.ndata['feat'].shape[0], 30)\n",
    "print(out2.shape)\n",
    "# with g.local_scope():\n",
    "#     g.ndata['feat'] = out2\n",
    "#     hg1 = dgl.readout_nodes(g, 'feat')\n",
    "#     print(hg1.shape)\n",
    "g.ndata['feat'] = out2\n",
    "hg = dgl.mean_nodes(g, 'feat')\n",
    "print(hg.shape)\n",
    "# he = dgl.mean_edges(g, 'feat')\n",
    "# print(he.shape)\n",
    "out3 = lin_layer(hg)\n",
    "print(out3.shape)\n",
    "\n",
    "# out1 = F.relu(layer1(g, g.ndata['feat']))\n",
    "# print(out1.shape)\n",
    "# out2 = F.relu(layer2(g, out1))\n",
    "# print(out2.shape)\n",
    "# g.ndata['h'] = out2\n",
    "# # dgl.unbatch(g)\n",
    "# dgl.mean_nodes(g, 'h').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.nn.pytorch as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_feats, edge_feats, out_feats, num_heads):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.in_feats = in_feats\n",
    "        self.edge_feats = edge_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.num_heads = num_heads\n",
    "        self.conv1 = dglnn.EdgeGATConv(in_feats, edge_feats, out_feats, num_heads, allow_zero_in_degree=True)\n",
    "        # self.conv2 = dglnn.EdgeGATConv(out_feats * num_heads, edge_feats, out_feats, num_heads, allow_zero_in_degree=True)\n",
    "        self.classify = nn.Linear(out_feats * num_heads, 1)\n",
    "\n",
    "    def forward(self, g, node_feat, edge_feat):\n",
    "        h = F.relu(self.conv1(g, node_feat, edge_feat))        \n",
    "        h = h.view(h.shape[0], self.out_feats * self.num_heads)\n",
    "        # h = F.relu(self.conv2(g, h, edge_feat))\n",
    "        # h = h.view(h.shape[0], self.out_feats * self.num_heads)\n",
    "        with g.local_scope():\n",
    "            g.ndata['feat'] = h\n",
    "            # Calculate graph representation by average readout.\n",
    "            hg = dgl.mean_nodes(g, 'feat')\n",
    "            # he = dgl.mean_edges(g, 'feat')\n",
    "            # hg = torch.cat([hg, he], dim=-1)``\n",
    "            return torch.sigmoid(self.classify(hg))\n",
    "        \n",
    "\n",
    "def f1_metric(logits, labels):\n",
    "    preds = (logits > 0.5).float()\n",
    "    return f1_score(labels.cpu().numpy(), preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_feats_dim = 768\n",
    "edge_feats_dim = 768\n",
    "out_feats = 15\n",
    "num_heads = 1\n",
    "model = Classifier(in_feats_dim, edge_feats_dim, out_feats, num_heads)\n",
    "model.load_state_dict(torch.load('GAT_model_10epochs_new.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    pred_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batched_graph, labels in data_loader:\n",
    "            # Move the entire graph to the specified device\n",
    "            batched_graph = batched_graph.to(device)\n",
    "\n",
    "            # Extract node and edge features after moving the graph to the right device\n",
    "            node_feat = batched_graph.ndata['feat']\n",
    "            edge_feat = batched_graph.edata['feat']\n",
    "\n",
    "            # Forward pass using the correct device\n",
    "            logits = model(batched_graph, node_feat, edge_feat).squeeze(1)\n",
    "\n",
    "            # Convert logits to numpy and make binary predictions\n",
    "            pred_probas = logits.cpu().numpy()\n",
    "            batch_pred_labels = (pred_probas >= 0.5) * 1\n",
    "\n",
    "            pred_labels.extend(batch_pred_labels)\n",
    "            \n",
    "\n",
    "    return pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict_and_write_tsv(model, data_loader, device, output_path):\n",
    "    # Make predictions\n",
    "    pred_labels = predict(model, data_loader, device)\n",
    "\n",
    "    # Assuming the data loader provides some form of sample identifier, you can build a list of IDs\n",
    "    sample_ids = range(len(pred_labels))  # Replace with actual sample identifiers if available\n",
    "\n",
    "    # Create a DataFrame to store predictions with sample IDs\n",
    "    results = pd.DataFrame({\n",
    "        \"sample_id\": sample_ids,\n",
    "        \"prediction\": pred_labels\n",
    "    })\n",
    "\n",
    "    # Write to a TSV file\n",
    "    results.to_csv(output_path, sep='\\t', index=False)\n",
    "\n",
    "# Example usage\n",
    "output_path = \"GAT_predictions_10epochs3.tsv\"\n",
    "predict_and_write_tsv(model, test_data, 'cpu', output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
