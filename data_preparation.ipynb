{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e6d3a21-9184-4a7f-a10c-0ace9a073858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from typing import Dict, Optional, Tuple, List\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, classification_report\n",
    "\n",
    "import dgl\n",
    "from dgl.data import MiniGCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4646fdf-4de4-4207-b51e-4852b7bdf1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1884b6be-b989-494a-be6b-4e53f7248ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fa8af06-7a03-44f6-9716-5f4bc25b933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_path = \"../data/tsv/train.tsv\"\n",
    "test_path = \"../data/tsv/test.tsv\"\n",
    "\n",
    "train_dev_df = pd.read_csv(train_dev_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76260307-6611-4ee7-8f29-a19fa4d4ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_questions = list(train_dev_df[\"question\"].unique())\n",
    "test_questions = list(test_df[\"question\"].unique())\n",
    "num_train_dev_questions = len(train_dev_questions)\n",
    "random.shuffle(train_dev_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a685308-beed-4e29-848c-087994c31fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1ed5360-18ce-42a9-b082-7848b986d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSimpleClassifier(nn.Module):\n",
    "    def __init__(self, bert_text_encoder, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert_text_encoder = bert_text_encoder\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        bert_hidden_dim = bert_text_encoder.config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bert_hidden_dim, bert_hidden_dim),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bert_hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs, attention_mask,):\n",
    "        last_hidden_states = self.bert_text_encoder(inputs, attention_mask=attention_mask,\n",
    "                                                    return_dict=True)['last_hidden_state']\n",
    "        text_cls_embeddings = torch.stack([elem[0, :] for elem in last_hidden_states])\n",
    "        proba = self.classifier(text_cls_embeddings)\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f60c489-f0a7-41a0-a745-34897463c8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Trainable params:  50206080\n"
     ]
    }
   ],
   "source": [
    "# model_name=\"roberta-base\"\n",
    "model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "freeze_embeddings = True\n",
    "if freeze_embeddings:\n",
    "    for param in bert_model.embeddings.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "freeze_layer_count = 5\n",
    "if freeze_layer_count > 0:\n",
    "    for layer in bert_model.encoder.layer[:freeze_layer_count]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "print(\"# Trainable params: \", sum(p.numel() for p in bert_model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "966f6d86-47d6-466e-8584-55df6560c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "DROPOUT = 0.2\n",
    "\n",
    "bert_simple_clf = BertSimpleClassifier(bert_model, dropout=DROPOUT).to(device)\n",
    "optimizer = optim.Adam(bert_simple_clf.parameters(), lr=3e-5)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b87b087-48c8-4d77-9c57-7fe7db84ef46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_simple_clf_trained = BertSimpleClassifier(bert_model, dropout=DROPOUT).to(device)\n",
    "bert_simple_clf_trained.load_state_dict(torch.load('best-val-text_only_baseline.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d31d8d-0aaa-4f98-b07e-da8593db71ab",
   "metadata": {},
   "source": [
    "#### Gettings embeddings for entities of nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56d2c30b-0c00-435d-86d3-f616c6b9a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_df[\"label\"] = train_dev_df[\"correct\"].astype(np.float32)\n",
    "train_dev_df[\"graph\"] = train_dev_df[\"graph\"].apply(eval)\n",
    "train_df_filtered_emb = train_dev_df.copy()\n",
    "train_df_filtered_emb = train_df_filtered_emb.drop_duplicates(subset=[\"question\", \"answerEntity\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80ad67-b6a1-446f-85bc-cf0ddeb80a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert None in labels to [MASK]\n",
    "def none2mask(row):\n",
    "    nodes = row['nodes']\n",
    "    edges = row['links']\n",
    "    for node in nodes:\n",
    "        if node['label'] is None:\n",
    "            node['label'] = '[MASK]'\n",
    "    for edge in edges:\n",
    "        if edge['label'] is None:\n",
    "            edge['label'] = '[MASK]'\n",
    "    return row\n",
    "\n",
    "train_df_filtered_emb['graph'] = train_df_filtered_emb['graph'].apply(none2mask)\n",
    "\n",
    "# create columns with labels of nodes and links (add [EMPTY] to empty list)\n",
    "def graph_labels(row, edges=False):\n",
    "    labels = []\n",
    "    if edges:\n",
    "        data = row['links']\n",
    "    else:\n",
    "        data = row['nodes']\n",
    "    for item in data:\n",
    "        labels.append(item['label'])\n",
    "    if len(labels)==0:\n",
    "        labels.append('[EMPTY]')\n",
    "    return labels\n",
    "\n",
    "\n",
    "train_df_filtered_emb['node_labels'] = train_df_filtered_emb['graph'].apply(graph_labels)\n",
    "train_df_filtered_emb['edge_labels'] = train_df_filtered_emb['graph'].apply(graph_labels, edges=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09579bcc-a347-43a4-bbfd-c934f6975de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper func \n",
    "def create_embs(model, tokenizer, data):\n",
    "    data_token = tokenizer(data, max_length=128, padding=\"max_length\", truncation=\"only_first\", return_tensors=\"pt\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = data_token[\"input_ids\"].to(device)\n",
    "        attention_mask = data_token[\"attention_mask\"].to(device)\n",
    "        outputs = model.bert_text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        outputs = outputs.last_hidden_state.mean(dim=1)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# create columns with embeddings in format suitable for dgl.data.CSVDataset\n",
    "def label_embs(row):\n",
    "    outputs = create_embs(bert_simple_clf_trained, tokenizer, row)\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    res = []\n",
    "    for output in outputs:\n",
    "        res.append(\",\".join(map(str, output)))\n",
    "    return res\n",
    "\n",
    "train_df_filtered_emb['node_embs'] = train_df_filtered_emb['node_labels'].apply(label_embs)\n",
    "train_df_filtered_emb['edge_embs'] = train_df_filtered_emb['edge_labels'].apply(label_embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47882c-0cfd-4179-aa6d-5773e1a06474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_filtered_emb.iloc[-1,-3]\n",
    "# функция для преобразования данных графа в csv\n",
    "def graph2node_csv(graph, id_graph, node_embs, edge_embs, edges=False):\n",
    "    output = []\n",
    "    if edges:\n",
    "        # one node cases (without edges) in order to avoid errors while forming dgl dataset\n",
    "        if len(graph['links']) == 0:\n",
    "            output.append(\n",
    "                {\n",
    "                    'graph_id': id_graph,\n",
    "                    'src_id': None,\n",
    "                    'dst_id': None,\n",
    "                    'feat': ' '\n",
    "                }\n",
    "            )\n",
    "        for i, item in enumerate(graph['links']):\n",
    "            output.append(\n",
    "                {\n",
    "                    'graph_id': id_graph,\n",
    "                    'src_id': item['source'],\n",
    "                    'dst_id': item['target'],\n",
    "                    'feat': edge_embs[i]\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        for i, item in enumerate(graph['nodes']):\n",
    "            output.append(\n",
    "                {\n",
    "                    'graph_id': id_graph,\n",
    "                    'node_id': item['id'],\n",
    "                    'feat': node_embs[i]\n",
    "                }\n",
    "            )\n",
    "    return output\n",
    "\n",
    "\n",
    "train_df_filtered_emb['node_csv'] = train_df_filtered_emb.apply(lambda x: graph2node_csv(x['graph'], x['sample_id'], x['node_embs'], x['edge_embs'], edges=False), axis=1)\n",
    "train_df_filtered_emb['edge_csv'] = train_df_filtered_emb.apply(lambda x: graph2node_csv(x['graph'], x['sample_id'], x['node_embs'], x['edge_embs'], edges=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7224a-af45-4728-8518-013f709f2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_of_nodes = train_df_filtered_emb['node_csv'].tolist()\n",
    "flattened_list_nodes = [item for sublist in lst_of_nodes for item in sublist]\n",
    "node_df = pd.DataFrame.from_records(flattened_list_nodes)\n",
    "\n",
    "lst_of_edges = train_df_filtered_emb['edge_csv'].tolist()\n",
    "flattened_list_edges = [item for sublist in lst_of_edges for item in sublist]\n",
    "edge_df = pd.DataFrame.from_records(flattened_list_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4338319-5ef9-43d6-8c97-b56d987866ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete one noode graphs for this time \n",
    "edge_df.dropna(how='any', axis=0, inplace=True)\n",
    "node_df = node_df[node_df['graph_id'].isin(edge_df.graph_id.tolist())]\n",
    "graph_df = train_df_filtered_emb.rename(columns={'sample_id':'graph_id'}).loc[:, ['graph_id', 'label']]\n",
    "graph_df = graph_df[graph_df['graph_id'].isin(edge_df.graph_id.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec9f13-fd30-4305-89e7-9f15f3f119f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df.to_csv('../data/dataset/edges.csv', index=False, na_rep=' ')\n",
    "node_df.to_csv('../data/dataset/nodes.csv', index=False)\n",
    "\n",
    "# train_df_filtered_emb[\"label\"] = train_df_filtered_emb[\"correct\"].astype(np.float32)\n",
    "# train_df_filtered_emb.rename(columns={'sample_id':'graph_id'}).loc[:, ['graph_id', 'label']].to_csv('../data/dataset/graphs.csv', index=False)\n",
    "\n",
    "graph_df.to_csv('../data/dataset/graphs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9e25170-f02a-4c95-8ba0-54fe1943e032",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "# create dgl dataset\n",
    "\n",
    "dataset = dgl.data.CSVDataset('../data/dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ad44889-6867-4ba6-899d-02d91369a142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35183"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1bae3d-9947-493d-824d-acccea450f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncmu_gainitdinov",
   "language": "python",
   "name": "ncmu_gainitdinov"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
